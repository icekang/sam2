{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fab7ba7-19fc-4e4b-bfd3-616f85544279",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "from PIL import Image\n",
    "import torch\n",
    "import os\n",
    "from sam2.build_sam import build_sam2_video_predictor\n",
    "import random\n",
    "\n",
    "random.seed(0)\n",
    "color_pallete = np.array([[0, 0, 0], [255, 0, 0], [0, 255, 0]])\n",
    "\n",
    "def load_ann_png(path):\n",
    "    \"\"\"Load a PNG file as a mask and its palette.\"\"\"\n",
    "    mask = Image.open(path)\n",
    "    palette = mask.getpalette()\n",
    "    mask = np.array(mask).astype(np.uint8)\n",
    "    return mask, palette\n",
    "\n",
    "def maximal_inscribed_circle(binary_label):\n",
    "    # Convert the label image to a binary image\n",
    "    binary_label = binary_label.astype(np.uint8)\n",
    "\n",
    "    dist_map = cv2.distanceTransform(binary_label, cv2.DIST_L2, cv2.DIST_MASK_PRECISE)\n",
    "    _, radius, _, center = cv2.minMaxLoc(dist_map)\n",
    "    return center, radius\n",
    "\n",
    "def add_prompt(video_label, predictor, inference_state, annotation_every_n):\n",
    "    video_length = Path(video_label).glob(\"*.png\")\n",
    "    video_length = len(list(video_length))\n",
    "    prompts = []\n",
    "    print('add_prompt/video_length', video_length)\n",
    "\n",
    "    prev_center = None\n",
    "    for i in range(0, video_length):\n",
    "        ann_obj_id = 1  # give a unique id to each object we interact with (it can be any integers)\n",
    "\n",
    "        mask, palette = load_ann_png(f'{video_label}/{i:05}.png')\n",
    "        mask_bool = np.all(mask == color_pallete[1].reshape(1, 1, 3), axis=2)\n",
    "        \n",
    "        if i % annotation_every_n != 0:\n",
    "            if i % annotation_every_n == 1:\n",
    "                center, radius = maximal_inscribed_circle(mask_bool) # already in x,y as they are the output from opencv\n",
    "                center = center[::-1]\n",
    "                random_point = np.array([center])\n",
    "                prev_center = random_point\n",
    "\n",
    "            mask_coords = np.argwhere(mask_bool)\n",
    "            if len(mask_coords) == 0:\n",
    "                continue\n",
    "            random_point = random.choice(mask_coords)\n",
    "            random_point = random_point[::-1]  # (y, x) -> (x, y)\n",
    "            random_point = np.array([random_point])\n",
    "\n",
    "            assert prev_center is not None, f\"prev_center should not be None at frame {i} while annotation is every {annotation_every_n} (modulo is {i % annotation_every_n})\"\n",
    "            labels = np.array([1], np.int32) # for labels, `1` means positive click and `0` means negative click\n",
    "            _, out_obj_ids, out_mask_logits = predictor.add_new_points_or_box(\n",
    "                inference_state=inference_state,\n",
    "                frame_idx=i,\n",
    "                obj_id=ann_obj_id,\n",
    "                points=prev_center,\n",
    "                labels=labels,\n",
    "            )\n",
    "            prompts.append({'type': 'point', 'frame': i, 'points': random_point})\n",
    "        else:\n",
    "            _, out_obj_ids, out_mask_logits = predictor.add_new_mask(\n",
    "                inference_state=inference_state,\n",
    "                frame_idx=i,\n",
    "                obj_id=ann_obj_id,\n",
    "                mask=mask_bool,\n",
    "            )\n",
    "            prompts.append({'type': 'mask', 'frame': i, 'mask': mask_bool})\n",
    "    return prompts\n",
    "\n",
    "def run_propagation(predictor, inference_state):\n",
    "    # run propagation throughout the video and collect the results in a dict\n",
    "    video_segments = {}  # video_segments contains the per-frame segmentation results\n",
    "    for out_frame_idx, out_obj_ids, out_mask_logits in predictor.propagate_in_video(inference_state):\n",
    "        video_segments[out_frame_idx] = {\n",
    "            out_obj_id: (out_mask_logits[i] > 0.0).cpu().numpy()\n",
    "            for i, out_obj_id in enumerate(out_obj_ids)\n",
    "    }\n",
    "    return video_segments\n",
    "\n",
    "def convert_video_segments_into_prediction_array(video_segments, object_id=1):\n",
    "    pred = [video_segments[frame_index][1] for frame_index in range(len(video_segments))]\n",
    "    pred = np.concatenate(pred, axis=0)\n",
    "    pred = pred.astype(np.uint8)\n",
    "    return pred\n",
    "\n",
    "def get_label_array(video_dir, video_label):\n",
    "    video_length = Path(video_dir).glob(\"*.jpg\")\n",
    "    video_length = len(list(video_length))\n",
    "    gt = []\n",
    "    for i in range(0, video_length):\n",
    "        mask, palette = load_ann_png(f'{video_label}/{i:05}.png')\n",
    "        mask_bool = np.all(mask == color_pallete[1].reshape(1, 1, 3), axis=2)\n",
    "        gt.append(mask_bool[None])\n",
    "\n",
    "    gt = np.concatenate(gt, axis=0)\n",
    "    gt = gt.astype(np.uint8)\n",
    "    return gt\n",
    "\n",
    "def dice_score_of_a_volume(gt, pred, ignore_index = 0):\n",
    "    labels = np.unique(gt)\n",
    "    dices = []\n",
    "    for label in labels:\n",
    "        if label == ignore_index:\n",
    "            continue\n",
    "        gt_bool = label == gt\n",
    "        pred_bool = label == pred\n",
    "        \n",
    "        intersection = np.logical_and(gt_bool, pred_bool)\n",
    "        dices.append(2. * intersection.sum() / (gt_bool.sum() + pred_bool.sum()))\n",
    "\n",
    "    avg_dice = sum(dices) / len(dices)\n",
    "    return labels, dices, avg_dice\n",
    "\n",
    "def run(model_cfg, sam2_checkpoint, output_name):\n",
    "\n",
    "    dataset_dir = Path('/home/gridsan/nchutisilp/datasets/nnUNet_Datasets/nnUNet_raw/Dataset302_Calcium_OCTv2/')\n",
    "    test_image_dir = dataset_dir / 'imagesTs'\n",
    "    test_label_dir = dataset_dir / 'labelsTs'\n",
    "\n",
    "\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    predictor = build_sam2_video_predictor(model_cfg, sam2_checkpoint, device=device)\n",
    "\n",
    "    resulting_dices_with_prompted_frames = []\n",
    "    resulting_dices_without_prompted_frames = []\n",
    "\n",
    "    for volume_path in test_label_dir.glob('*.nii.gz'):\n",
    "        filename = volume_path.name.replace('.nii.gz', '')\n",
    "\n",
    "        video_dir = f'/home/gridsan/nchutisilp/datasets/SAM2_Dataset302_Calcium_OCTv2/imagesTs/{filename}'\n",
    "        video_label = f'/home/gridsan/nchutisilp/datasets/SAM2_Dataset302_Calcium_OCTv2/labelsTs/{filename}'\n",
    "        inference_state = predictor.init_state(video_path=video_dir)\n",
    "\n",
    "        annotation_every_n=4\n",
    "        prompts = add_prompt(video_label, predictor, inference_state, annotation_every_n)\n",
    "        video_segments = run_propagation(predictor, inference_state)\n",
    "        prediction_output = Path(f'./{output_name}_annotate_every_{annotation_every_n}/')\n",
    "        prediction_output.mkdir(exist_ok=True)\n",
    "        torch.save(video_segments, prediction_output / f\"video_segments_{filename}.pt\")\n",
    "        torch.save(prompts, prediction_output / f\"prompts_{filename}.pt\")\n",
    "\n",
    "        pred = convert_video_segments_into_prediction_array(video_segments, object_id=1)\n",
    "        gt = get_label_array(video_dir, video_label)\n",
    "\n",
    "        labels, dices, avg_dice = dice_score_of_a_volume(gt, pred)\n",
    "        print('Dice including prompted frames of', filename, ':', avg_dice)\n",
    "        resulting_dices_with_prompted_frames.append(avg_dice)\n",
    "\n",
    "        selector_mask = np.ones(gt.shape[0])\n",
    "        selector_mask[::annotation_every_n] = 0\n",
    "        selector_mask = selector_mask.astype(np.bool)\n",
    "        labels, dices, avg_dice = dice_score_of_a_volume(gt[selector_mask], pred[selector_mask])\n",
    "        print('Dice excluding prompted frames of ', filename, ':', avg_dice)\n",
    "        resulting_dices_without_prompted_frames.append(avg_dice)\n",
    "\n",
    "\n",
    "    print('Average dice including prompted frames:', sum(resulting_dices_with_prompted_frames) / len(resulting_dices_with_prompted_frames))\n",
    "    print('Average dice excluding prompted frames:', sum(resulting_dices_without_prompted_frames) / len(resulting_dices_without_prompted_frames))\n",
    "    print('Done')\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     run(\"configs/sam2.1/sam2.1_hiera_s.yaml\", \"/home/gridsan/nchutisilp/projects/segment-anything-2/sam2_logs/configs/sam2.1_training/sam2.1_hiera_s_MOSE_finetune_scale4_var1.yaml/checkpoints/checkpoint.pt\", \"sam2.1_hiera_s_MOSE_finetune_scale4_var1.yaml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20bbb4b0-d2ee-41aa-8f7d-669e472c3173",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "\n",
    "def maximal_inscribed_circle(binary_label):\n",
    "    # Convert the label image to a binary image\n",
    "    binary_label = binary_label.astype(np.uint8)\n",
    "\n",
    "    dist_map = cv2.distanceTransform(binary_label, cv2.DIST_L2, cv2.DIST_MASK_PRECISE)\n",
    "    _, radius, _, center = cv2.minMaxLoc(dist_map)\n",
    "    return center, radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a7fd7a8-e11e-410b-bcec-68ddb4120c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cfg = \"configs/sam2.1/sam2.1_hiera_s.yaml\"\n",
    "sam2_checkpoint = \"/home/gridsan/nchutisilp/projects/segment-anything-2/sam2_logs/configs/sam2.1_training/sam2.1_hiera_s_MOSE_finetune_scale4_var1.yaml/checkpoints/checkpoint.pt\"\n",
    "dataset_dir = Path('/home/gridsan/nchutisilp/datasets/nnUNet_Datasets/nnUNet_raw/Dataset302_Calcium_OCTv2/')\n",
    "test_image_dir = dataset_dir / 'imagesTs'\n",
    "test_label_dir = dataset_dir / 'labelsTs'\n",
    "\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "predictor = build_sam2_video_predictor(model_cfg, sam2_checkpoint, device=device)\n",
    "\n",
    "resulting_dices_with_prompted_frames = []\n",
    "resulting_dices_without_prompted_frames = []\n",
    "\n",
    "for volume_path in test_label_dir.glob('*.nii.gz'):\n",
    "    filename = volume_path.name.replace('.nii.gz', '')\n",
    "\n",
    "    video_dir = f'/home/gridsan/nchutisilp/datasets/SAM2_Dataset302_Calcium_OCTv2/imagesTs/{filename}'\n",
    "    video_label = f'/home/gridsan/nchutisilp/datasets/SAM2_Dataset302_Calcium_OCTv2/labelsTs/{filename}'\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87fd8138-5c66-47ee-982a-0cae8714f719",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_length = Path(video_label).glob(\"*.png\")\n",
    "video_length = len(list(video_length))\n",
    "prompts = []\n",
    "\n",
    "prev_center = None\n",
    "for i in range(0, video_length):\n",
    "    ann_obj_id = 1  # give a unique id to each object we interact with (it can be any integers)\n",
    "\n",
    "    mask, palette = load_ann_png(f'{video_label}/{i:05}.png')\n",
    "    mask_bool = np.all(mask == color_pallete[1].reshape(1, 1, 3), axis=2)\n",
    "    \n",
    "    mask_coords = np.argwhere(mask_bool)\n",
    "    if len(mask_coords) > 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04a8fe19-2cfc-4b57-b669-edd881b8ce23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_center_of_maximal_inscribed_circle_in_xy(mask_bool):\n",
    "    center, _ = maximal_inscribed_circle(mask_bool) # already in x,y as they are the output from opencv\n",
    "    return np.array([center])\n",
    "\n",
    "prev_center_xy = np.array([])\n",
    "prev_positive_prompts_yx = np.array([])\n",
    "prev_center_xy = get_center_of_maximal_inscribed_circle_in_xy(mask_bool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "680abca8-7bbb-43ef-9a0a-107bd40338f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294 210\n"
     ]
    }
   ],
   "source": [
    "# random_point is x,y due to opencv\n",
    "random_point_x, random_point_y = random_point[0]\n",
    "\n",
    "# mask_corrds is y, x due to numpy\n",
    "[random_point_x, random_point_y] in mask_coords\n",
    "# [random_point_x, random_point_y] in mask_coords\n",
    "for y, x in mask_coords:\n",
    "    if random_point_x == x and random_point_y == y:\n",
    "        print(y, x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "32f0076a-49fc-4040-bad4-384646a04e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.typing as npt\n",
    "def filter_points_outside_mask(points_in_yx: npt.NDArray[np.int64], mask_bool: npt.NDArray[np.int64]) -> npt.NDArray[np.int64]:\n",
    "    if not points_in_yx.size:\n",
    "        return points_in_yx\n",
    "    \n",
    "    return points_in_yx[mask_bool[points_in_yx[:, 0], points_in_yx[:, 1]]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b06329b7-57c3-4b61-b16c-6876d1072b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sample_points = 10\n",
    "prev_positive_prompts_yx = np.array(random.choices(mask_coords, k=n_sample_points - len(prev_positive_prompts_yx)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b79a7318-b4ee-4bf8-b58b-000e47db6748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[305, 227],\n",
       "       [303, 213],\n",
       "       [293, 213],\n",
       "       [288, 202],\n",
       "       [296, 209],\n",
       "       [293, 201],\n",
       "       [304, 207],\n",
       "       [289, 215],\n",
       "       [295, 209],\n",
       "       [298, 211]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev_positive_prompts_yx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9cf7bb4a-7561-4a25-ab34-209bf286874f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 2), dtype=int64)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_coords = np.argwhere(mask_bool)\n",
    "neg_mask_coords = np.argwhere(~mask_bool)\n",
    "\n",
    "prev_positive_prompts_yx = np.array(random.choices(mask_coords, k=n_sample_points))\n",
    "prev_neg_prompts_yx = np.array(random.choices(neg_mask_coords, k=n_sample_points))\n",
    "random_points = np.concatenate((prev_positive_prompts_yx, prev_neg_prompts_yx), axis=0)\n",
    "filter_points_outside_mask(prev_neg_prompts_yx, mask_bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b57d03b8-33c0-4cc0-9579-7e3e2c1c1f1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev_positive_prompts_yx.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e4aa6114-3eb0-4cad-a9ef-80a55bf5ace1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 2), dtype=float64)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ndarray(shape=(0, 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-sam2]",
   "language": "python",
   "name": "conda-env-.conda-sam2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
